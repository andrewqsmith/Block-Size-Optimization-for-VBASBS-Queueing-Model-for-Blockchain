\documentclass[conference]{IEEEtran}
%\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{listings}
\usepackage{fancyvrb}
\usepackage{xcolor}
\usepackage[makeroom]{cancel}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Adapting VBASBS Queueing Model for Proof-of-Stake Consensus Algorithm}

\author{
  \textbf{Kyle Kentner, Nathan Crosby, Andrew Smith, Sush Chittibabu, and Abdulla Karjikar}\\
  Oklahoma State University - Stillwater, OK \\
  kyle.kentner@okstate.edu, ncrosby@okstate.edu, scu@okstate.edu, \\
  sushmitha.chittibabu@okstate.edu, abdulla.karjikar@okstate.edu}

\maketitle

\begin{abstract}

Our main goal with this work is to establish a theoretical model that can simulate
more accurately how blockchain transactions are grouped, validated, processed,
and purged from a network based on a proof-of-stake consensus algorithm. With 
the switch from the proof-of-work consensus algorithm to the newer proof-of-stake with 
cryptocurrencies, most notably Ethereum, there is a need to update the theoretical 
models that are used to define efficiency metrics. Further, we took it upon ourselves 
to move beyond that and quantify the optimal time window to decrease waiting time
for the average owner of each transaction, while not significantly deteriorating throughput
for the network as a whole.

\end{abstract}

\begin{IEEEkeywords}
Blockchain, Optimization, Queueing
\end{IEEEkeywords}

\section{Introduction}\label{Intro}

The blockchain, a distributed ledger utilizing records linked together via cryptographic 
hashes, has within the last decade captivated the industry. Having been utilized in the 
development of a decentralized economic transfer scheme with the adoption of 
Bitcoin\cite{2008_Bitcoin_Nakamoto}, the original proof-of-work concept had established 
a means of validating incoming transactions through a distributed network of participants. 
This led to the development of other crypto-currency applications, most notably Ethereum. 
These solutions implemented methods with a focus on the accuracy and redundancy of the 
various transactions with minimal effort given to reduce individual transactional waiting 
time and increase the efficiency of processing transactions.

This approach remains true for Bitcoin; however, Ethereum changed this consensus 
mechanism in 2022 with the update to proof-of-stake\cite{2022_Ethereum_PoS}. This 
changed the blockchain to be more efficient in reducing complexity in the work 
computations while decreasing the barrier to entry hence providing reduced centralized 
risk with the potential of more nodes securing the network. Where under the proof-of-work
consensus algorithm, the timing of blocks was determined by the mining difficulty, the 
new approach, proof-of-stake, the timing is fixed. Time in the Ethereum proof-of-stake 
consensus algorithm is divided into slots of 12 seconds and epochs of 32 slots.

While the proof-of-stake greatly improved the efficiency of transactions, there remains 
room for improvements in the validation of transactions. In this paper, we propose an 
algorithm to decrease waiting time while maintaining a high level of throughput. To begin 
the optimization process, we must first choose a performance model that analytically 
describes the relationship between the number of transactions, the fixed time for those 
transactions to be processed, and the total number of transactions that are processed 
(throughput). Once a representative performance model has been chosen, an optimal
time window can be selected that balances out the throughput. 

Our paper is organized as follows. In section two we conduct a brief literature review and 
then focus on the performance model that will underly our own work. Section three is 
dedicated to the methodology we used to optimize the block size with details of our 
approach theorized via mathematical models. In section four, we discuss the results recorded 
from our early attempts at simulating our proposed model. Then we conclude in section five 
with remarks and discuss potential future areas to continue expanding upon the model. 

\section{Related Work}\label{related}

One of the main detriments of the concept of cryptocurrencies has been the slow transaction
rates with proof-of-work consensus algorithm validation of transactions. The main focus to rectify 
this problem while maintaining the original consensus algorithm can be seen in previous work such 
as Fu\cite{2020_IEEEToVT_Fu}. This work states that when considering blockchain optimization, 
the throughput, or number of transactions processed by a blockchain system in a given amount of 
time, are key indicators of its performance. Mechkaroska\cite{2018_TELFOR_Mechkaroska} explores
some of the methods tried up to that point. They include increasing the block size to increase the 
number of transactions being processed, which is increasing throughput, and a technique called 
"sharding" that is similar to parallel processing of transactions. This showed up in an alt-coin named 
Zilliqa\cite{2017_Zilliqa_Zilliqa} which is mentioned in the paper. While sharding is on the docket of 
potential changes to the Ethereum network, it has not been given the green light yet, and might not
be necessary considering the changes made to the consensus algorithm, discussed later.

The prevalence of articles that called for an increase to the block size to a na\"ive larger size shows 
a lack of creativity to solve this issue of slow transaction validation as can be seen in Gobel, Thakkar, 
and Mechkaroska\cite{2017_IEEE_Gobel, 2018_IEEE_Thakkar, 2018_TELFOR_Mechkaroska}. The 
hard fork in Bitcoin to create Bitcoin Cash was chiefly designed to make this change, with the increase 
in block size from 1MB on Bitcoin to 8MB on Bitcoin Cash. 

Proof-of-work consensus algorithms take such a long time to calculate as a safety precaution against
Sybil attacks. This methodology is no longer required for large market cap cryptocurrencies, and a 
shift to a proof-of-stake consensus algorithm facilitates a precipitous drop in energy consumption
as seen in Platt\cite{2021_IEEEQRSC_Platt}. The large pool of staked validators means that the 
requirement for a validator can switch from access to raw compute power to capital. As stated in 
Sec.~\ref{Intro} this change for Ethereum happened in 2022, and therefore a new theoretical model
must be considered to take into account the eccentricities of this new consensus algorithm. 

\section{Methodology}

\subsection{Original Performance Model}\label{Model}
Our algorithm will expand on the performance model proposed by Seol, Kancharla, Ke, Kim and Park
 - A Variable Bulk Arrival and Static Bulk Service Queuing Model for Blockchain\cite{2020_ACM_Seol}. 
 In the initial model, the arrival rate of the individual blockchain transactions is variable, but not unpredictable. 
 The arrival rate is assumed to vary with the size of the incoming transaction and the rate is 
 denoted by the symbol $\lambda$.

The variable $\mu$ is defined to be the processing time of a block to be posted and purged as noted 
in Seol\cite{2020_ACM_Seol}, and is assumed to be fairly static as stated in the model. 
The variable n is defined to be the total number of slots in the block. P$_i$ denotes the states with 
P$_n$ denoting the maximum state before the block is processed. 

This model was based off of a proof-of-work concept as can primarily be seen with cryptocurrencies 
such as Bitcoin, as stated in Sec.~\ref{Intro}. The crux of the argument for this balance set of equations 
lies in Eq. 1 in Seol\cite{2020_ACM_Seol}, and also here, and thus will be the basis for our 
new model. 

\begin{equation}
P_n = \frac{\lambda}{\mu}\frac{n(n+1)}{2}P_0\label{om_1}
\end{equation}

\subsection{New Performance Model}\label{new_model}

\begin{figure*}[htbp]
    \centerline{\includegraphics[width=\textwidth]{Figures/FlowDiagram.png}}
    \caption{State transition diagram of new model.} 
    \label{flow}
\end{figure*}	

Due to the ethereum network switching from the proof-of-work to proof-of-stake 
concept for their consensus algorithm, as discussed in Sec. ~\ref{related}, we have decided to update
the base model in Seol\cite{2020_ACM_Seol} to reflect this new regime. This 
new proof-of-stake methodology essentially flips the previous base model on its 
head, where the time between blocks being pushed out to validators is set at twelve 
seconds, and because of this, the block size can then fluctuate based 
on the number of transactions that have arrived in the latest block window of time. 

The subsequently updated variables and assumptions are given below. 

$P_{0,0}$: The state at which no time has passed in the block window of time ($T$). 

$P_{t,0}$: The state at all of the time has passed in the block window of time ($T$), and
the block is ready to be sent to the validator community, with no empty time slices ($j$) so 
$n = t$. 

$P_{t-j,j}$: The state where all of the time has passed in the block window of time ($T$), and
the block is ready to be sent to the validator community, with $j$ empty time slices ($j$). 

$P_{i,0}$: The state at which $i$ transactions have arrived in the 
block window of time with 0 empty time slices ($j$). 

$P_{i,j}$: The state at which $i$ transactions have arrived in the 
block window of time with $j$ empty time slices ($j$). 

$\tau$: The minimum time increment that can pass between the 
transaction arrivals. If the theoretical maximum for a given application is 1,000 transactions 
per second then $\tau = \frac{1}{1000}$

$T$: The total time that will pass between each block creation and is initially static.

$t$: The total number of transactions that can be seen in one block window of time.
This is calculated as $\frac{T}{\tau}$, therefore if $T$ is fixed at twelve seconds and
$\tau=\frac{1}{1000}$ then $t=\frac{12}{\frac{1}{1000}}=12,000$. 

$\Omega$: The rate for the entire block to be posted and purged. This is assumed
to balance the new form of equations as $\mu$ did in the original base model.

$n$: The number of transactions in the block. This is now dependent on $j$ which is
the number of empty time slices that has been seen in the current block window. Here, 
$n=t - j$ or the total possible transactions, minus the empty time slices ($j$) seen in the
block window of time

\subsubsection{$P_{0,0}$} $\\$

The initial state must be set up based on the state transition diagram given in Fig.~\ref{flow}.
Based on that diagram the incoming and outgoing transitions are given below which yields the 
balanced equation in Eq.~\ref{nm_1}. $\\$

\begin{figure}[htbp]
    \centerline{\includegraphics[width=\linewidth]{Figures/StateTransition2.jpg}}
    \caption{State Transition Diagram of $P_{0,0}$} 
    \label{trans1}
\end{figure}	

Incoming from $P_{t,0}$, $P_{t-1,1}$, $P_{t-2,2}$, ... , $P_{2,t-2}$, $P_{1,t-1}$

Outgoing to $P_{1,0}$, $P_{1,1}$, $P_{1,2}$, ... , $P_{1,t-2}$, $P_{1,t-1}$

\begin{multline}
\Omega(P_{t,0} + P_{t-1,1} + P_{t-2,2} + ... + P_{2,t-2} + P_{1,t-1})\\
= \tau(1 + 2 + 3 + ... + t-1 + t)P_{0,0}\label{nm_1}
\end{multline}

Here we have the summation from $1$ to $t$ which can be rewritten as 
$\frac{t(t+1)}{2}$ and the other summation is all of the possible ending states
before we return to $P_{0,0}$. This can then be rewritten in Eq. ~\ref{nm_2}.

\begin{equation}
\Omega\sum_{j=0}^{t-1}{P_{t-j,j}} = \tau\frac{t(t+1)}{2}P_{0,0}\label{nm_2}
\end{equation}

As can be seen here, our new set of equations will be based on time instead of 
a set number of transactions filling up a block. Our newly added parameter $j$ for 
the time slices without a transaction present are essentially a stall cycle of waiting 
for the next transaction to arrive and has the effect of splitting the final state, 
$P_t$ from the base model in Seol\cite{2020_ACM_Seol} into various states 
from $0$ empty time slices up to $t-1$ empty time slices. In the event of $t$ 
empty time slices there would be no transactions to validate and the model 
would loop back to $P_{0,0}$. 

It is with this addition, along with chopping a fixed amount of time to minimum time
increments, $\tau$, that we can approximate the proof of stake workflow in 
blockchain networks, like Ethereum. 

\subsubsection{$P_{i,0}$} $\\$

From here we need to expand in two directions, namely $i$ and $j$. In the equations,
we denote the transactions that are incoming to the network, with a maximum of one
per time slice ($\tau$). The variable $j$ is then time slices without a transaction present.

Incoming from $\tau P_{0,0}$

Outgoing to $\frac{(t-i-j)(t-i-j+1)}{2} P_{1,0}$

\begin{equation}
  \bcancel{\tau}P_{0,0} = \\
  \bcancel{\tau}\frac{(t-i-j)(t-i-j+1)}{2}P_{1,0}\label{nm_3}
\end{equation}

\begin{equation}
  P_{1,0} = \frac{2}{(t-1)t}P_{0,0}\label{nm_4}
\end{equation}

Similarly, we can expand to $P_{2,0}$ from $P_{1,0}$ with Eqs.~\ref{nm_5} \&~\ref{nm_6}

\begin{equation}
  \bcancel{\tau}P_{1,0} = \\
  \bcancel{\tau}\frac{(t-i-j)(t-i-j+1)}{2}P_{2,0}\label{nm_5}
\end{equation}

\begin{equation}
  P_{2,0} = \frac{2}{(t-i-j)(t-i-j+1)}P_{1,0}\label{nm_6}
\end{equation}

Then subbing in for $P_{1,0}$ from Eq.~\ref{nm_4}:

\begin{equation}
  P_{2,0} = \frac{2}{(t-2)(t-1)}\frac{2}{(t-1)t}P_{0,0}\label{nm_7}
\end{equation}

And similarly for $P_{3,0}$ we get Eq.~\ref{nm_8}:

\begin{equation}
  P_{3,0} = \frac{2}{(t-3)(t-2)}\frac{2}{(t-2)(t-1)}\frac{2}{(t-1)t}P_{0,0}\label{nm_8}
\end{equation}

And we can see the pattern emerge for the generalized $P_{i,0}$:

\begin{equation}
  P_{i,0} = \frac{2^i}{(t-i)t\prod_{k=1}^{i-1}{(t-i+k)^2}}P_{0,0}\label{nm_9}
\end{equation}

\subsubsection{$P_{i,j}$} $\\$

Here, we are going to shift to adding stall cycles, or empty time slices to the set of 
balanced equations derived from the state transition diagram in Fig.~\ref{flow}. This 
involves increasing our variable j. We will show this by transitioning from from 
$P_{1,0}$ to $P_{1,1}$ first and then extrapolate from there. Eq.~\ref{nm_4} gives us 
the starting point of $P_{1,0}$, so then:

\begin{figure}[htbp]
    \centerline{\includegraphics[width=\linewidth]{Figures/StateTransition4.jpg}}
    \caption{State Transition Diagram of $P_{i,j}$} 
    \label{trans2}
\end{figure}	

Incoming from $\tau P_{1,0}$

Outgoing to $\frac{(t-i-j)(t-i-j+1)}{2} P_{1,1}$

\begin{equation}
  \bcancel{\tau}P_{1,0} = \\
  \bcancel{\tau}\frac{(t-i-j)(t-i-j+1)}{2}P_{1,1}\label{nm_10}
\end{equation}

\begin{equation}
  P_{1,1} = \frac{2}{(t-2)(t-1)}P_{1,0}\label{nm_11}
\end{equation}

We can now substitute Eq.~\ref{nm_4} back into Eq.~\ref{nm_11}
and after grouping like terms we have:

\begin{equation}
  P_{1,1} = \frac{2^2}{(t-2)(t-1)^2n}P_{0,0}\label{nm_12}
\end{equation}

Extrapolating on this point we can now derive and equation for 
$P_{1, 2}$ as: 

\begin{equation}
  \bcancel{\tau}P_{1,1} = \\
  \bcancel{\tau}\frac{(t-i-j)(t-i-j+1)}{2}P_{1,2}\label{nm_13}
\end{equation}

\begin{equation}
  P_{1,2} = \frac{2}{(t-2)(t-1)}P_{1,1}\label{nm_14}
\end{equation}

\begin{equation}
  P_{1,2} = \frac{2^3}{(t-3)(t-2)^2(t-1)^2n}P_{0,0}\label{nm_15}
\end{equation}

We can now generalize this for any $P_{i,j}$ as:

\begin{equation}
  P_{i,j} = \frac{2^{(i+j)}}{(t-i-j)t\prod_{k=1}^{(i+j)-1}{(t-i-j+k)^2}}P_{0,0}\label{nm_16}
\end{equation}

\subsubsection{$P_{t-j,j}$} $\\$

We have defined the initial state, $P_{0,0}$, with the summation of all of the
final states, $P_{t-j,j}$, but to fully describe the state transition diagram in 
Fig.~\ref{flow} we must define the individual $P_{t-j,j}$. The impetus for this 
set of equations can be seen in Fig.~\ref{trans3}. We will start with the case 
that all time slices, $\tau$, have a transaction present, and therefore $j$ is 
zero. 

\begin{figure}[htbp]
    \centerline{\includegraphics[width=\linewidth]{Figures/StateTransition3.jpg}}
    \caption{State Transition Diagram of $P_{t-j,j}$} 
    \label{trans3}
\end{figure}

Incoming from $\tau P_{t-1,0}$ 

Outgoing to $\Omega P_{t,0}$

\begin{equation}
  \tau P_{t-1,0} = \Omega P_{t,0}\label{nm_17}
\end{equation}

Substituting in for $P_{t-1,0}$ and solving for $P_{t,0}$ we then have:

\begin{equation}
  P_{t,0}  = \frac{\tau}{\Omega} \frac{2^{t-1}}{(t-1)\prod_{k=1}^{t-2}{(k+1)^2}}P_{0,0}\label{nm_18}
\end{equation}

\subsubsection{Constraint: Markovian Queueing Assumption}

\begin{equation}
P_{0,0} + \sum_{i=1}^{t}{\sum_{j=0}^{t-i}{P_{i,j}}} = 1.0\label{nm_20}
\end{equation}

\subsubsection{Remarks} $\\$

$\bullet$ Each $P_{i,j}$ depends on the previous $(i-1)$ column and its 
preceding $(0 ... j)$ rows. This $P_{i,j}$ in turn, affects $P_{i+1,j}$ through
$P_{i+1,t-i-1}$.

$\bullet$ The $i=0$ column has only $P_{0,0}$ (no arrivals and no time 
elapsed.

\subsection{Optimization}\label{optimization}

Optimization in the old base model pertained to maximizing throughput
while minimizing waiting time by adjusting the size of the next bloc, $n$,
based on the expected rate of transaction arrivals, $\lambda$. 

Since we have now flipped the model on its head and time is fixed for the next
block sent to validators and the block size already varies, we set out to see if
we can loosen this constraint and set an optimal $T$ based on how fast 
transactions are reaching the network. In our new model, this is entirely based
on $j$ since that variable represents time slices, $\tau$, with no transactions in them,
or as we have also stated, each $j$ can be thought of as a stall cycle waiting for
the next transaction to arrive.

Throughput is then the number of transactions in a given amount of time. 

\begin{equation}
  Throughput = \frac{n}{T}\label{opt_1}
\end{equation}

As is stated in the definitions at the beginning of Sec.~\ref{new_model},
$n=t-j$ and also $t = \frac{T}{\tau}$, so we then have:

\begin{equation}
  Throughput = \frac{\frac{T}{\tau}-j}{T}=\frac{1}{\tau}-\frac{j}{T}\label{opt_2}
\end{equation}

The waiting time for each customer in the queue is now simply $T$

\begin{equation}
  \frac{Throughput}{WaitingTime} = \frac{\frac{1}{\tau}-\frac{j}{T}}{T} = \frac{1}{\tau T}-\frac{j}{T^2}\label{opt_2}
\end{equation}

To find the optimal level of $T$ we then need to take the partial derivative with respect to $T$ that will
be in terms of $j$ and then set it equal to zero and solve for $T$. For simplicity in Eq.~\ref{opt_3}, 
let's call the ratio of Throughput to Waiting Time $M$, and we can calculate the derivative as follows.

\begin{equation}
  \frac{\delta M}{\delta T} = -\frac{1}{\tau T^2}+\frac{2j}{T^3}=0\label{opt_3}
\end{equation}

\begin{equation}
  \frac{1}{\tau T^2}T^3=\frac{2j}{T^3}T^3\label{opt_4}
\end{equation}

\begin{equation}
  T=2j\tau \label{opt_5}
\end{equation}

It is therefore shown that, based on our new model for proof-of-stake networks, the optimal 
time window is two times the number of stall cycles $j$ times the size of the time slice $\tau$.
Since $\tau$ is known and a technical requirement of the network (theoretical max transactions
per second), we only need to estimate $j$ for the coming period to then broadcast the next time 
window $T$ when the previous block is sent out to be validated. For practical purposes, the 
ceiling of the solution to Eq.~\ref{opt_5} should be used to make sure that the time interval is always at least one
second and that there are discrete second intervals to choose from.

\iffalse
\subsection{Closed Form Optimization}\label{closed_opt}

This semester, we can start by removing the iterative, numerical process described above with 
a closed-form solution to get the optimal n. The first thing then is that we have to look at the metric.
In the iterative process, we had the ratio of throughput over waiting time multiplied by a plug of $n lg(n)$. 

Let's then look at the equations of throughput and waiting time to see how the ratio looks when reducing it. 
W$_Q$ is given in eq. \ref{WQ_eq} as simply L$_Q$ divided by $\lambda$, so lets write that out and 
show that $\lambda$ cancels out in that equation.

\begin{equation}
W_Q=\frac{n\ast\frac{\lambda}{\mu}\frac{n(n+1)}{2}P_0}{\lambda}=n\ast\frac{\cancel{\lambda}}{\mu}\frac{n(n+1)}{2}P_0\ast\frac{1}{\cancel{\lambda}}\label{WQ_reduced}
\end{equation}

Eq. \ref{gamma_eq} gives the equation for $\gamma$, so if we look at the equation for the ratio of throughput over waiting time we get eq. \ref{ratio_eq}. 

\begin{equation}
\frac{\gamma}{W_Q}=\frac{\lambda\cancel{\frac{n(n+1)}{2}}\cancel{P_0}}{\frac{n}{\mu}\cancel{\frac{n(n+1)}{2}}\cancel{P_0}}=\frac{\lambda}{\frac{n}{\mu}}=\frac{\mu}{n}\ast\lambda\label{ratio_eq}
\end{equation}

Now, this ratio when reduced shows that throughput over waiting time is a monotonically increasing function, 
with $\mu$ being fixed this means that $n$ is directly dependent on $\lambda$. This would not lead to an optimal 
level of $n$, but rather as $\lambda$ became smaller (or quicker), $n$ would become smaller. In practice, 
batching was necessary to process transactions more efficiently, so there should be some penalty for having blocks 
that are too small. The particular network or application would probably have a direct impact on this number, but
for our case in an arbitrary blockchain, let's set this to $\frac{1}{3n^3}$. In this way, when $n$ gets very small, 
the penalty gets larger. A maximum can also be determined based on network processing speeds as a cap to 
$n$. So, now we have eq. \ref{metric_eq} which we can denote $M$ for metric.

\begin{equation}
M=\frac{\gamma}{W_Q}-penalty=\frac{\mu\lambda}{n}-\frac{1}{3n^3}\label{metric_eq}
\end{equation}

To find the maximum/minimum of this equation we need to take the first derivative with respect to $n$ 
and set it equal to zero. 

\begin{equation}
\frac{\delta M}{\delta n}=-\frac{\mu\lambda}{n^2}+\frac{1}{n^4}=0\label{metric_deriv}
\end{equation}

Then solving for $n$ we have eqs. \ref{cf_opt_n_1}, \ref{cf_opt_n_2}, \ref{cf_opt_n_3}.

\begin{equation}
-\frac{\mu\lambda}{n^2}=-\frac{1}{n^4}\label{cf_opt_n_1}
\end{equation}

\begin{equation}
\frac{n^4}{n^2}=\frac{1}{\mu\lambda}\label{cf_opt_n_2}
\end{equation}

\begin{equation}
n=\frac{1}{\sqrt{\mu\lambda}}\label{cf_opt_n_3}
\end{equation}

We now have the closed-form solution that the optimal block size ($n$) is inversely related to
the square root of the cost of creating a block ($\mu$) times the speed with which the transactions 
are coming into the network($\lambda$). 

Using this same equation, $\lambda$ can also be projected based on the cyclical nature of how transaction
speeds progress throughout the day and the optimal $n$ can be calculated before each block is created to 
predetermine the next block size to be created. 
\fi

\section{Results}

TODO: Redo this later

\section{Conclusion and discussion}

The conclusion this team has derived through the suggested mathematical models is that the blockchain transactions,
in regards to proof-of stack, can be optimized in the model described in Seol\cite{2020_ACM_Seol}. This is achievable, 
as suggested in Sec. III, through time variable transactions into the queuing model. In this proposed solution, a
significant reduction is noticeable in transaction waiting time in the queue while maintaining acceptable levels of
throughput.

Additional research recommended would be to expand this methodology into a future Ethereum branch where sharding
has been implemented. We believe that this approach, along with asynchronous composability inherited from the necessity
for the splltting of the Ethereum infrastructure, would facilitate optimization on the various transactional validation 
required on such a scale.

\bibliographystyle{IEEEtrans}
\bibliography{Crosby}

\end{document}
